{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(seq_len, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pre = torch.ones(3, 5, 2, dtype=torch.float64)\n",
    "out_pre[1,:,:] *= 2\n",
    "out_pre[2,:,:] *= 3\n",
    "hidden_post = torch.randint(-10, -1, size=(5,2), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4., -8.],\n        [-4., -6.],\n        [-3., -7.],\n        [-7., -5.],\n        [-5., -7.]], dtype=torch.float64)\ntensor([[[1., 1.],\n         [1., 1.],\n         [1., 1.],\n         [1., 1.],\n         [1., 1.]],\n\n        [[2., 2.],\n         [2., 2.],\n         [2., 2.],\n         [2., 2.],\n         [2., 2.]],\n\n        [[3., 3.],\n         [3., 3.],\n         [3., 3.],\n         [3., 3.],\n         [3., 3.]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(hidden_post)\n",
    "print(out_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.,  -3.],\n",
       "         [ -7., -10.],\n",
       "         [ -9.,  -9.],\n",
       "         [ -8.,  -3.],\n",
       "         [ -3.,  -5.]],\n",
       "\n",
       "        [[ -8.,  -6.],\n",
       "         [-14., -20.],\n",
       "         [-18., -18.],\n",
       "         [-16.,  -6.],\n",
       "         [ -6., -10.]],\n",
       "\n",
       "        [[-12.,  -9.],\n",
       "         [-21., -30.],\n",
       "         [-27., -27.],\n",
       "         [-24.,  -9.],\n",
       "         [ -9., -15.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pre * hidden_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_soft = torch.sum((out_pre * hidden_post), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -7., -17., -18., -11.,  -8.],\n",
       "        [-14., -34., -36., -22., -16.],\n",
       "        [-21., -51., -54., -33., -24.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.,  -3.],\n",
       "        [ -7., -10.],\n",
       "        [ -9.,  -9.],\n",
       "        [ -8.,  -3.],\n",
       "        [ -3.,  -5.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_a, u_a, v_a = torch.randn(2,2, dtype=torch.float64), torch.randn(2,2, dtype=torch.float64), torch.randn(2,1, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6756, -1.3255],\n",
       "        [ 0.8864,  0.1925]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[3., 3.],\n",
       "         [3., 3.],\n",
       "         [3., 3.],\n",
       "         [3., 3.],\n",
       "         [3., 3.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5619, -1.1331],\n",
       "         [ 1.5619, -1.1331],\n",
       "         [ 1.5619, -1.1331],\n",
       "         [ 1.5619, -1.1331],\n",
       "         [ 1.5619, -1.1331]],\n",
       "\n",
       "        [[ 3.1238, -2.2662],\n",
       "         [ 3.1238, -2.2662],\n",
       "         [ 3.1238, -2.2662],\n",
       "         [ 3.1238, -2.2662],\n",
       "         [ 3.1238, -2.2662]],\n",
       "\n",
       "        [[ 4.6857, -3.3992],\n",
       "         [ 4.6857, -3.3992],\n",
       "         [ 4.6857, -3.3992],\n",
       "         [ 4.6857, -3.3992],\n",
       "         [ 4.6857, -3.3992]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(out_pre, w_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0929,  1.9116],\n",
       "        [17.2361,  7.2713],\n",
       "        [16.8229,  6.1607],\n",
       "        [ 8.0342,  1.3435],\n",
       "        [ 8.3754,  3.7067]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(hidden_post, u_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_soft = torch.matmul(out_pre, w_a) + torch.matmul(hidden_post, u_a)\n",
    "pre_soft = torch.tanh(pre_soft).matmul(v_a).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2542, 0.3333, 0.3330, 0.2674, 0.3070],\n",
       "        [0.3417, 0.3333, 0.3331, 0.3532, 0.3158],\n",
       "        [0.4041, 0.3334, 0.3338, 0.3794, 0.3772]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(pre_soft, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_soft = F.softmax(pre_soft, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2542, 0.3333, 0.3330, 0.2674, 0.3070],\n",
       "        [0.3417, 0.3333, 0.3331, 0.3532, 0.3158],\n",
       "        [0.4041, 0.3334, 0.3338, 0.3794, 0.3772]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pre.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = torch.sum(out_pre.permute(2, 0, 1) * post_soft, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1498, 2.1498],\n",
       "        [2.0001, 2.0001],\n",
       "        [2.0008, 2.0008],\n",
       "        [2.1121, 2.1121],\n",
       "        [2.0701, 2.0701]], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amphibian.networks.LSTM import LSTMModel\n",
    "from amphibian.networks.attention import AttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seq_len = 30\n",
    "input_size = 120\n",
    "my_batch = torch.randn(batch_size, seq_len, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMModel(batch_size=batch_size, seq_len=seq_len, input_size=input_size, hidden_size=10, n_outputs=3,\n",
    "                 num_layers=2, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out = lstm(my_batch.permute(1,0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test by checking if all gradients change during a backward pass. We define a dummy target tensor and use simple L2 loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(batch_size, 3)\n",
    "loss_fun = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN dotprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_rnn = AttentionModel(batch_size=batch_size, seq_len=seq_len, input_size=input_size, hidden_size=10, n_outputs=3,\n",
    "                          num_layers=2, dropout=0.1)\n",
    "\n",
    "optimizer = optim.SGD(attn_rnn.parameters(), lr=1)\n",
    "attn_rnn_out = attn_rnn(my_batch.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2920, 0.2192, 0.2202], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_rnn.parameters())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_opt = copy.deepcopy(attn_rnn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurrent_pre.weight_ih_l0 torch.Size([10, 120])\n",
      "recurrent_pre.weight_hh_l0 torch.Size([10, 10])\n",
      "recurrent_pre.bias_ih_l0 torch.Size([10])\n",
      "recurrent_pre.bias_hh_l0 torch.Size([10])\n",
      "recurrent_pre.weight_ih_l1 torch.Size([10, 10])\n",
      "recurrent_pre.weight_hh_l1 torch.Size([10, 10])\n",
      "recurrent_pre.bias_ih_l1 torch.Size([10])\n",
      "recurrent_pre.bias_hh_l1 torch.Size([10])\n",
      "recurrent_cell_post.weight_ih torch.Size([10, 10])\n",
      "recurrent_cell_post.weight_hh torch.Size([10, 10])\n",
      "recurrent_cell_post.bias_ih torch.Size([10])\n",
      "recurrent_cell_post.bias_hh torch.Size([10])\n",
      "fc.weight torch.Size([3, 10])\n",
      "fc.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, ten in attn_rnn.state_dict().items():\n",
    "    print(name, ten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurrent_pre.weight_ih_l0 tensor(0.8174)\n",
      "recurrent_pre.weight_hh_l0 tensor(0.1195)\n",
      "recurrent_pre.bias_ih_l0 tensor(0.1143)\n",
      "recurrent_pre.bias_hh_l0 tensor(0.1143)\n",
      "recurrent_pre.weight_ih_l1 tensor(0.9262)\n",
      "recurrent_pre.weight_hh_l1 tensor(1.4349)\n",
      "recurrent_pre.bias_ih_l1 tensor(0.5261)\n",
      "recurrent_pre.bias_hh_l1 tensor(0.5261)\n",
      "recurrent_cell_post.weight_ih tensor(2.8797)\n",
      "recurrent_cell_post.weight_hh tensor(2.3095)\n",
      "recurrent_cell_post.bias_ih tensor(0.8826)\n",
      "recurrent_cell_post.bias_hh tensor(0.8826)\n",
      "fc.weight tensor(1.7004)\n",
      "fc.bias tensor(0.6380)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fun(attn_rnn_out, y)\n",
    "attn_rnn.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "# Print differences in gradients\n",
    "for pre, post in zip(pre_opt.items(), attn_rnn.state_dict().items()):\n",
    "    print(pre[0], torch.sum(torch.abs(pre[1] - post[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2020, -0.0618, -0.0469], requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_rnn.parameters())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_rnn_ffnn = AttentionModel(batch_size=batch_size, seq_len=seq_len, input_size=input_size, hidden_size=10, n_outputs=3,\n",
    "                               num_layers=2, dropout=0.1, alignment='ffnn')\n",
    "\n",
    "optimizer = optim.SGD(attn_rnn_ffnn.parameters(), lr=1)\n",
    "attn_rnn_ffnn_out = attn_rnn_ffnn(my_batch.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.6149e-01,  1.4842e-05,  5.5488e-02], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_rnn_ffnn.parameters())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_opt = copy.deepcopy(attn_rnn_ffnn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_a torch.Size([10, 10])\n",
      "u_a torch.Size([10, 10])\n",
      "v_a torch.Size([10, 1])\n",
      "recurrent_pre.weight_ih_l0 torch.Size([10, 120])\n",
      "recurrent_pre.weight_hh_l0 torch.Size([10, 10])\n",
      "recurrent_pre.bias_ih_l0 torch.Size([10])\n",
      "recurrent_pre.bias_hh_l0 torch.Size([10])\n",
      "recurrent_pre.weight_ih_l1 torch.Size([10, 10])\n",
      "recurrent_pre.weight_hh_l1 torch.Size([10, 10])\n",
      "recurrent_pre.bias_ih_l1 torch.Size([10])\n",
      "recurrent_pre.bias_hh_l1 torch.Size([10])\n",
      "recurrent_cell_post.weight_ih torch.Size([10, 10])\n",
      "recurrent_cell_post.weight_hh torch.Size([10, 10])\n",
      "recurrent_cell_post.bias_ih torch.Size([10])\n",
      "recurrent_cell_post.bias_hh torch.Size([10])\n",
      "fc.weight torch.Size([3, 10])\n",
      "fc.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, ten in attn_rnn_ffnn.state_dict().items():\n",
    "    print(name, ten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_a tensor(0.1741)\n",
      "u_a tensor(0.0188)\n",
      "v_a tensor(0.0480)\n",
      "recurrent_pre.weight_ih_l0 tensor(0.4393)\n",
      "recurrent_pre.weight_hh_l0 tensor(0.0607)\n",
      "recurrent_pre.bias_ih_l0 tensor(0.0657)\n",
      "recurrent_pre.bias_hh_l0 tensor(0.0657)\n",
      "recurrent_pre.weight_ih_l1 tensor(0.3176)\n",
      "recurrent_pre.weight_hh_l1 tensor(0.6208)\n",
      "recurrent_pre.bias_ih_l1 tensor(0.2742)\n",
      "recurrent_pre.bias_hh_l1 tensor(0.2742)\n",
      "recurrent_cell_post.weight_ih tensor(1.4279)\n",
      "recurrent_cell_post.weight_hh tensor(2.1454)\n",
      "recurrent_cell_post.bias_ih tensor(0.5945)\n",
      "recurrent_cell_post.bias_hh tensor(0.5945)\n",
      "fc.weight tensor(1.8058)\n",
      "fc.bias tensor(0.4990)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fun(attn_rnn_ffnn_out, y)\n",
    "attn_rnn_ffnn.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "# Print differences in gradients\n",
    "for pre, post in zip(pre_opt.items(), attn_rnn_ffnn.state_dict().items()):\n",
    "    print(pre[0], torch.sum(torch.abs(pre[1] - post[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0390, -0.0107, -0.2104], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_rnn_ffnn.parameters())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_lstm = AttentionModel(batch_size=batch_size, seq_len=seq_len, input_size=input_size, hidden_size=10, n_outputs=3,\n",
    "                           num_layers=2, dropout=0.1, alignment='ffnn', recurrent_type='lstm')\n",
    "\n",
    "optimizer = optim.SGD(attn_lstm.parameters(), lr=1)\n",
    "attn_lstm_out = attn_lstm(my_batch.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0163, -0.1729,  0.0629], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_lstm.parameters())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_opt = copy.deepcopy(attn_lstm.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_a torch.Size([10, 10])\n",
      "u_a torch.Size([10, 10])\n",
      "v_a torch.Size([10, 1])\n",
      "recurrent_pre.weight_ih_l0 torch.Size([40, 120])\n",
      "recurrent_pre.weight_hh_l0 torch.Size([40, 10])\n",
      "recurrent_pre.bias_ih_l0 torch.Size([40])\n",
      "recurrent_pre.bias_hh_l0 torch.Size([40])\n",
      "recurrent_pre.weight_ih_l1 torch.Size([40, 10])\n",
      "recurrent_pre.weight_hh_l1 torch.Size([40, 10])\n",
      "recurrent_pre.bias_ih_l1 torch.Size([40])\n",
      "recurrent_pre.bias_hh_l1 torch.Size([40])\n",
      "recurrent_cell_post.weight_ih torch.Size([40, 10])\n",
      "recurrent_cell_post.weight_hh torch.Size([40, 10])\n",
      "recurrent_cell_post.bias_ih torch.Size([40])\n",
      "recurrent_cell_post.bias_hh torch.Size([40])\n",
      "fc.weight torch.Size([3, 10])\n",
      "fc.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, ten in attn_lstm.state_dict().items():\n",
    "    print(name, ten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_a tensor(0.0002)\n",
      "u_a tensor(2.7465e-06)\n",
      "v_a tensor(3.3846e-05)\n",
      "recurrent_pre.weight_ih_l0 tensor(0.0968)\n",
      "recurrent_pre.weight_hh_l0 tensor(0.0025)\n",
      "recurrent_pre.bias_ih_l0 tensor(0.0009)\n",
      "recurrent_pre.bias_hh_l0 tensor(0.0009)\n",
      "recurrent_pre.weight_ih_l1 tensor(0.0127)\n",
      "recurrent_pre.weight_hh_l1 tensor(0.0086)\n",
      "recurrent_pre.bias_ih_l1 tensor(0.0110)\n",
      "recurrent_pre.bias_hh_l1 tensor(0.0110)\n",
      "recurrent_cell_post.weight_ih tensor(0.0518)\n",
      "recurrent_cell_post.weight_hh tensor(0.0533)\n",
      "recurrent_cell_post.bias_ih tensor(0.0636)\n",
      "recurrent_cell_post.bias_hh tensor(0.0636)\n",
      "fc.weight tensor(0.1401)\n",
      "fc.bias tensor(0.1688)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fun(attn_lstm_out, y)\n",
    "attn_lstm.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "# Print differences in gradients\n",
    "for pre, post in zip(pre_opt.items(), attn_lstm.state_dict().items()):\n",
    "    print(pre[0], torch.sum(torch.abs(pre[1] - post[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0390, -0.0107, -0.2104], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(attn_rnn_ffnn.parameters())[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
